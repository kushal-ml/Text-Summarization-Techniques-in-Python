# Text-Summarization-Techniques-in-Python
Text Summarization Techniques in Python
This project aims to create three different abstractive summarization agents using deep learning techniques and compare their performance. To work on this project. I divided the workflow into these steps –
1.Data collection
2.Model Architectures
3.Calculate evaluation metrics and compare the performance of each model

For the dataset, I have downloaded an article named “Global, regional, and national burden of disorders affecting the nervous system, 1990–2021: a systematic analysis for the Global Burden of Disease Study 2021 “ from the dataset named “Bag of Words” from the Machine Learning Repository of UCI. The article contains the summary and its contents. With my model, I have used contents to summarize it and compare it with an original summary to calculate the rouge score.

I have included the pdf of the article in the zip file along with .ipynb and .py files.

As per instructions, I worked with abstractive summarization models for model architectures. Abstractive summarization can generate human-like summaries by understanding the input text and rephrasing it concisely and coherently. The three models I used are T5, BART, and Pegasus. These all are advanced abstractive summarization models based on Transformer architecture. T5 model - Text-To-Text Transfer Transformer is trained in a unified text-to-text framework, where input and output are represented as text strings. This framework enables T5 to handle various NLP tasks using a single architecture, including summarization, translation, question answering, and more. BART -Bidirectional and Auto-Regressive Transformers is based on the Transformer architecture and combines elements of bidirectional and auto-regressive models. It uses a denoising autoencoding objective, where the model is trained to corrupt and reconstruct input text. Pegasus is based on the Transformer architecture and is designed explicitly for abstractive text summarization. It utilizes a self-supervised pre-training objective called Gap sentence generation (GSG), where the model learns to fill in gaps in document-sentence pairs. I have used the rouge score to compare each model's performance. ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It is a set of metrics commonly used for
evaluating the quality of summaries generated by text summarization models. ROUGE measures the overlap between the generated summary and original summaries 

STEPS FOR THIS PROJECT – 
#STEP 1 - IMPORT ALL THE REQUIRED LIBRARIES 
#STEP 2 - EXTRACT THE TEXT FROM THE ARTICLE WHICH IS IN PDF FORMAT 
#STEP 3 - DEFINE ALL THE THREE MODELS FOR TEXT SUMMARIZATION, I.E., T5, BART AND PEGASUS 
#STEP 4 - CALL ALL THE MODELS AND FIND SUMMARY FOR EACH MODEL 
#STEP 5 - INITIALIZE THE ORIGINAL SUMMARY OF THE DOCUMENT 
#STEP 6 - CALCULATE THE ROUGE SCORES FOR EACH MODEL


OUTPUT Below is the table of the original summary and the summary generated by three different models.

SUMMARY ORIGINAL Disorders affecting the nervous system are diverse and include neurodevelopmental disorders, late-life neurodegeneration, and newly emergent conditions, such as cognitive impairment following COVID-19. Previous publications from the Global Burden of Disease, Injuries, and Risk Factor Study estimated the burden of 15 neurological conditions in 2015 and 2016, but these analyses did not include neurodevelopmental disorders, as defined by the International Classification of Diseases (ICD)-11, or a subset of cases of congenital, neonatal, and infectious conditions that cause neurological damage. Here, we estimate nervous system health loss caused by 37 unique conditions and their associated risk factors globally, regionally, and nationally from 1990 to 2021 

T5-
Diseases affecting the nervous system are diverse and include neurodevelopmental disorders, late-life neurodegeneration, and newly emergent conditions, such as cognitive impairment following COVID-19. We estimate nervous system health loss caused by 37 unique conditions and their associated risk factors globally, regionally, and nationally from 1990 to 2021. Globally, the 37 conditions affecting the nervous system were collectively ranked as the leading group. 

BART-  We estimate nervous system health loss caused by 37 unique conditions and their associated risk factors globally, regionally, and nationally from 1990 to 2021. We included morbidity and deaths due to neurological conditions, for which health loss is directly due to damage to the CNS or peripheral nervous system. Globally, the 37 conditions affecting the nervous system were collectively ranked as the leading group cause of death. 

PEGASUS - 
The global burden of disorders affecting the nervous system has increased by 18% between 1990 and 2021 to 40 billion individuals, affecting 40% of the global population, according to a systematic analysis. The World Health Organization (WHO) and the International Agency for Research on Cancer (IARC) have published global data on disease burden of disorders affecting the nervous system (DALYs) for the period 1990 to 2021.

ROUGE SCORES –
The three ROUGE scores represent the performance of a summarization model in terms of three different evaluation metrics:
ROUGE-1: Measures overlap of unigrams (single words) between the generated summary and the reference summary. It calculates recall (R), precision (P), and F1 score (F) based on the presence of unigrams in both summaries.
ROUGE-2: Similar to ROUGE-1, but it considers the overlap of bigrams (pairs of adjacent words) between the generated summary and the reference summary.
ROUGE-L: This metric computes the longest common subsequence of words between the generated summary and the reference summary. It measures the recall, precision, and F1 score based on the longest common subsequence.
OUTPUT -
1.
T5:
•
ROUGE-1: R=0.5, P=0.8163, F=0.6202
•
ROUGE-2: R=0.42, P=0.7241, F=0.5316
•
ROUGE-L: R=0.5, P=0.8163, F=0.6202
2.
BART:
•
ROUGE-1: R=0.3875, P=0.6327, F=0.4806
•
ROUGE-2: R=0.24, P=0.3871, F=0.2963
•
ROUGE-L: R=0.35, P=0.5714, F=0.4341
3.
Pegasus:
•
ROUGE-1: R=0.1625, P=0.2955, F=0.2097
•
ROUGE-2: R=0.07, P=0.1186, F=0.0881
•
ROUGE-L: R=0.15, P=0.2727, F=0.1935
ANALYSIS - T5 consistently outperforms BART and Pegasus across all ROUGE metrics. It achieves the highest F1 scores for ROUGE-1, ROUGE-2, and ROUGE-L, indicating that it generates summaries that are closer to the original summaries in terms of both recall and precision.
BART performs better than Pegasus but lags behind T5. While it achieves moderate F1 scores, they are notably lower than T5. Pegasus consistently has the lowest ROUGE scores among the three models, indicating poorer performance. Its summaries have lower recall, precision, and F1 scores than T5 and BART.
T5 is the best-performing summarization model among T5, BART, and Pegasus
